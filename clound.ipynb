{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"clound.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"veoF7081ST3q","colab_type":"code","outputId":"343a2c07-5100-4fce-d503-292beb2c5ab3","executionInfo":{"status":"ok","timestamp":1569598222230,"user_tz":-480,"elapsed":4296,"user":{"displayName":"chen jiang","photoUrl":"","userId":"17563235988389824821"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["#加载云盘\n","from google.colab import drive\n","drive.mount('/content/drive')\n","#改变工作目录\n","import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/DF/clound/')\n","!ls\n","\n","#过12个小时 空间就会被自动清理\n","n = len(os.listdir('trainImg/'))\n","if n > 10000: \n","    print(\"train有图像{}张\".format(n))\n","else:\n","    os.chdir('/content/drive/My Drive/Colab Notebooks/DF/clound/trainImg')\n","    !ls\n","    !unzip -o Train.zip\n","    os.chdir('/content/drive/My Drive/Colab Notebooks/DF/clound/')\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","clound.ipynb\t    train1111.tfrecords  Train_label.csv\n","submit_example.csv  trainImg\t\t train_single.tfrecords\n","train有图像10669张\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ydzNU3EnTbid","colab_type":"code","outputId":"48b7e99a-443d-473e-b0a1-0af812c63428","executionInfo":{"status":"ok","timestamp":1569598223570,"user_tz":-480,"elapsed":5606,"user":{"displayName":"chen jiang","photoUrl":"","userId":"17563235988389824821"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import tensorflow as tf\n","import numpy as np\n","import keras\n","import keras.backend as K\n","from keras.preprocessing.image import ImageDataGenerator\n","import matplotlib.pyplot as plt\n","import cv2\n","from PIL import Image\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","\n","Train_Img_Dir = 'trainImg/'\n","Train_Label_Path = 'Train_label.csv'\n","Test_Img_Dir = 'testImg/'\n","TS_TFRecords_File = 'train_single.tfrecords' #单标签的图片tfrecoard\n","TM_TFRecords_File = 'train_multi.tfrecords' #多标签的图片tfrecoard\n","submit_File = 'submit_example.csv'\n","\n","X_shape = [500, 500, 3] # 预处理后图像的大小\n","EPOCH = 100 # 训练多少轮\n","Batch_size = 128  # 训练的batch size\n","\n","# tf.enable_eager_execution() #调试用\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mQ8KUGgNezn9","colab_type":"code","colab":{}},"source":["def read_image(name, type):\n","    \"\"\"读图片 并把Image类型转成numpy\n","    name: 图片名\n","    type: ‘train' 'test'\n","    \"\"\"\n","    if type == 'train':\n","        path = os.path.join(Train_Img_Dir, name)\n","    elif type == 'test': \n","        path = os.path.join(Test_Img_Dir, name)\n","\n","    img = Image.open(path) # img.mode = 'RGB'\n","    if img.mode != 'RGB':\n","        img = img.convert(\"RGB\") #读取图片的过程中如果遇到非'RGB'就转换格式\n","    img_array = np.asarray(img, np.float32)\n","    # plt.imshow(img)  \n","    # plt.show()\n","    return img_array \n","\n","class DatasetGenerator:\n","    def __init__(self):\n","        self.tls = self._get_train_label() #获取训练图片名列表\n","        #获取单标签的训练图片名和label列表\n","        self.train_single_labels = self.tls[self.tls.apply(lambda x: len(x['Code'])<=2, axis=1)] \n","        self.train_single_num = len(self.train_single_labels) #图片总数\n","        #获取多标签的训练图片名和label列表(label长度2个以上)\n","        self.train_multi_labels = self.tls[self.tls.apply(lambda x: len(x['Code'])>2, axis=1)]  \n","        self.train_multi_num = len(self.train_multi_labels) #图片总数\n","        #单标签 标签类别数目，也是网络最后一层的单元数目\n","        self.single_class_num = len(self.train_single_labels['Code'].unique()) \n","\n","    def write2TFRecoard(self, type, start=0, end=None, option=None):\n","        \"\"\"\n","        #把图片生成TFRecords文件\n","        type: TFRecord文件的存放路径\n","        start, end: 保存图片的\n","        option: TFRecord文件保存的压缩格式\n","        \"\"\"\n","        #待写 start end参数检查 但是超出index范围没关系 \n","        if type == 'single': #选择的是单标签的图片\n","            tfr_file = TS_TFRecords_File\n","            nls = self.train_single_labels\n","        elif type == 'multi':\n","            tfr_file = TM_TFRecords_File\n","            nls = self.train_multi_labels\n","\n","        trf_writer = tf.python_io.TFRecordWriter(tfr_file, options=option)\n","\n","        nls = nls.sample(frac=1).reset_index(drop=True)    #打乱顺序 frac是要返回的比例 1=100%\n","        for index, (name, label) in nls[start:end].iterrows():\n","            img = read_image(name, 'train')\n","            img_shape = img.shape\n","            img = img.reshape(-1) #变成一维\n","            img = self.__preprocessing(img) #裁剪 归一化等预处理\n","            img_list = img.tolist() \n","            feature_internal = {\n","                    'image_raw' : tf.train.Feature(float_list = tf.train.FloatList(value=img_list)), #内层feature编码方式\n","                    'img_shape' : tf.train.Feature(int64_list = tf.train.Int64List(value=img_shape)),\n","                    'label' : tf.train.Feature(int64_list = tf.train.Int64List(value=[int(label)]))     \n","                    }\n","            #使用tf.train.Example将features编码数据封装成特定的PB协议格式\n","            example = tf.train.Example(features=tf.train.Features(feature=feature_internal))\n","            #将序列化为字符串的example数据写入协议缓冲区\n","            print('No.{}: trf_writer写入{} label:{}'.format(index, name, label))\n","            trf_writer.write(example.SerializeToString())\n","        #关闭TFRecords文件操作接口    \n","        trf_writer.close()\n","\n","    def get_from_TFRecoard(self, tfr_files=TS_TFRecords_File, batch_size=None):\n","        \"\"\"\n","        ##从tfr_files指定的TFRecords文件，初始化一个dataset\n","        :param \n","            tfr_files: TFRecords文件路径\n","            batch_size: 参数表示batch的消息 None不处理 \n","        :return: \n","        \"\"\"\n","        # 定义TFRecordDataset\n","        dataset = tf.data.TFRecordDataset(tfr_files) #默认一个文件\n","        dataset = dataset.shuffle(buffer_size=1000)\n","        #执行解析函数 得到数据集    \n","        dataset = dataset.map(self.__parse_function)\n","        # 定义batchsize大小\n","        if batch_size:\n","            dataset = dataset.batch(batch_size)\n","        # 不加参数->无限重复数据集\n","        dataset = dataset.repeat()\n","        return dataset\n","\n","    def __preprocessing(self, img):\n","        \"\"\"对图像数据进行预处理\"\"\"\n","        #其他处理。。。\n","        # img_norm = tf.image.per_image_standardization(timg) #tensorflow中对图像标准化预处理的API\n","        img_norm = img/255.  #[0,1]归一化\n","        return img_norm\n","\n","    def __parse_function(self, example_proto):\n","        \"\"\"解析函数 \n","        :param example_proto: example序列化后的样本tf_serialized\n","        \"\"\"\n","        features = {\n","            'image_raw' : tf.VarLenFeature(dtype=tf.float32),\n","            'img_shape' : tf.FixedLenFeature(shape=(3,), dtype=tf.int64),\n","            'label' : tf.FixedLenFeature(shape=(), dtype=tf.int64)\n","            }\n","        # 把序列化样本和解析字典送入函数里得到解析的样本\n","        parsed_example = tf.parse_single_example(example_proto, features) #返回字典\n","        # 解码 \n","        img = tf.sparse_tensor_to_dense(parsed_example['image_raw'], default_value=0) # 稀疏->密集表示\n","        img = tf.reshape(img, parsed_example['img_shape']) # 转换tensor形状\n","        # 如果使用dataset作为keras中，model.fit函数等的参数，则需要使用one_hot编码\n","        # 在tensorflow中，基本是不需要的，可以直接返回example['label']。\n","        # label = tf.one_hot(parsed_example['label'], self.train_single_num)\n","        # label = tf.cast(parsed_example['label'], tf.uint8)\n","        label = parsed_example['label']\n","        return img, label\n","\n","    def _get_train_label(self):\n","        \"\"\"获取所有的train label\"\"\"\n","        labels = pd.read_csv(Train_Label_Path)\n","        return labels\n","\n","    def _get_train_img(self, start=0, end=100):\n","        \"\"\"测试用 读图片\"\"\"\n","        for i in range(start, end):\n","            (name, label) = dg.train_labels.iloc[i]        \n","            img = read_image(name, 'train')\n","            yield(img, label)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fQfqGdcaLc5R","colab_type":"code","outputId":"fa4ecac3-9dcf-4e25-c7d2-fe3e5aec691e","executionInfo":{"status":"ok","timestamp":1569599720733,"user_tz":-480,"elapsed":890,"user":{"displayName":"chen jiang","photoUrl":"","userId":"17563235988389824821"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"source":["# 以下测试\n","dg = DatasetGenerator()\n","sess = tf.InteractiveSession() \n","sess.run(tf.global_variables_initializer())"],"execution_count":39,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py:1735: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n","  warnings.warn('An interactive session is already active. This can '\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"d8Ir1UTELmjh","colab_type":"code","colab":{}},"source":["# dg.write2TFRecoard('single',0,5) #写入到tfrecoard\n","# dg.write2TFRecoard() #写入到tfrecoard"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VcCF0MsjDWah","colab_type":"code","colab":{}},"source":["dataset = dg.get_from_TFRecoard(tfr_files=TS_TFRecords_File)\n","# dataset = dg.get_from_TFRecoard(tfr_files='train1111.tfrecords')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2nmIarDiSK_8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"727430db-8e74-4191-8931-6c5c5a407c0c","executionInfo":{"status":"ok","timestamp":1569598531972,"user_tz":-480,"elapsed":783,"user":{"displayName":"chen jiang","photoUrl":"","userId":"17563235988389824821"}}},"source":["# dataset.make_one_shot_iterator().get_next()"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<tf.Tensor 'IteratorGetNext_27:0' shape=(?, ?, ?, ?) dtype=float32>,\n"," <tf.Tensor 'IteratorGetNext_27:1' shape=(?,) dtype=int64>)"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"8C2erHkyWEbW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":250},"outputId":"5cdb3cad-7742-4445-d4b3-adc4ccb8c48c","executionInfo":{"status":"error","timestamp":1569599739575,"user_tz":-480,"elapsed":972,"user":{"displayName":"chen jiang","photoUrl":"","userId":"17563235988389824821"}}},"source":["iterator = dataset.make_one_shot_iterator()\n","for i in range(6):\n","    imgs, labels = iterator.get_next()\n","    # print('Epoch.{} batch={}'.format(i, batch))\n","    print('img: ',imgs, '\\nlabel: ',labels)\n","    # for j in imgs:\n","    image = imgs[0].eval()\n","    # print('No.{} image shape:'.format(i+1), image.shape)\n","    plt.imshow(image[:,:,0])\n","    plt.show()"],"execution_count":41,"outputs":[{"output_type":"stream","text":["img:  Tensor(\"IteratorGetNext_32:0\", shape=(?, ?, ?), dtype=float32) \n","label:  Tensor(\"IteratorGetNext_32:1\", shape=(), dtype=int64)\n"],"name":"stdout"},{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-7db0edfd7426>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# print('No.{} image shape:'.format(i+1), image.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for array"]}]},{"cell_type":"code","metadata":{"id":"S3lFIoSNGy2K","colab_type":"code","colab":{}},"source":["label.eval()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"igamoy5w6692","colab_type":"code","colab":{}},"source":["dg.train_multi_labels\n","dg.train_multi_num, dg.train_single_num"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"II6xL_B0rVlR","colab_type":"code","colab":{}},"source":["d = dg.train_single_labels[:10].copy()\n","d['Code'] = range(10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fO297UoyKojD","colab_type":"code","colab":{}},"source":["timg, l = next(dg._get_train_img()) #取测试图片"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r_f4k6pGdtIr","colab_type":"code","colab":{}},"source":["timg"],"execution_count":0,"outputs":[]}]}